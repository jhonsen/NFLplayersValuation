{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow of preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect and clean stats data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ScrapeProcFunc import *\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url reached,  https://www.pro-football-reference.com/draft/2000-combine.htm\n",
      "url reached,  https://www.pro-football-reference.com/draft/2001-combine.htm\n",
      "url reached,  https://www.pro-football-reference.com/draft/2002-combine.htm\n",
      "url reached,  https://www.pro-football-reference.com/draft/2003-combine.htm\n",
      "url reached,  https://www.pro-football-reference.com/draft/2004-combine.htm\n",
      "url reached,  https://www.pro-football-reference.com/draft/2005-combine.htm\n",
      "url reached,  https://www.pro-football-reference.com/draft/2006-combine.htm\n",
      "url reached,  https://www.pro-football-reference.com/draft/2007-combine.htm\n",
      "url reached,  https://www.pro-football-reference.com/draft/2008-combine.htm\n",
      "url reached,  https://www.pro-football-reference.com/draft/2009-combine.htm\n",
      "url reached,  https://www.pro-football-reference.com/draft/2010-combine.htm\n",
      "url reached,  https://www.pro-football-reference.com/draft/2011-combine.htm\n",
      "url reached,  https://www.pro-football-reference.com/draft/2012-combine.htm\n",
      "url reached,  https://www.pro-football-reference.com/draft/2013-combine.htm\n",
      "url reached,  https://www.pro-football-reference.com/draft/2014-combine.htm\n",
      "finished collecting soups\n",
      "finished making variables\n",
      "finished making dictionaries\n",
      "finished making dataframes\n",
      "\n",
      " 15 Pandas df's created, which are:\n",
      "\n",
      "dfcomb_2000\n",
      "dfcomb_2001\n",
      "dfcomb_2002\n",
      "dfcomb_2003\n",
      "dfcomb_2004\n",
      "dfcomb_2005\n",
      "dfcomb_2006\n",
      "dfcomb_2007\n",
      "dfcomb_2008\n",
      "dfcomb_2009\n",
      "dfcomb_2010\n",
      "dfcomb_2011\n",
      "dfcomb_2012\n",
      "dfcomb_2013\n",
      "dfcomb_2014\n"
     ]
    }
   ],
   "source": [
    "#1.  Make a list of dataframes containing NFL-Combines Data\n",
    "list_df_Combines = createDFs('comb', 2000, 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url reached,  https://www.pro-football-reference.com/years/2000/rushing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2001/rushing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2002/rushing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2003/rushing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2004/rushing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2005/rushing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2006/rushing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2007/rushing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2008/rushing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2009/rushing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2010/rushing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2011/rushing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2012/rushing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2013/rushing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2014/rushing.htm\n",
      "finished collecting soups\n",
      "finished making dictionaries\n",
      "finished making dataframes\n",
      "\n",
      " 15 Pandas df's created, which are:\n",
      "\n",
      "dfrush_2000\n",
      "dfrush_2001\n",
      "dfrush_2002\n",
      "dfrush_2003\n",
      "dfrush_2004\n",
      "dfrush_2005\n",
      "dfrush_2006\n",
      "dfrush_2007\n",
      "dfrush_2008\n",
      "dfrush_2009\n",
      "dfrush_2010\n",
      "dfrush_2011\n",
      "dfrush_2012\n",
      "dfrush_2013\n",
      "dfrush_2014\n"
     ]
    }
   ],
   "source": [
    "#2.  Make a list of dataframes containing Rushing stats, 2018-2014\n",
    "list_df_Rush = createDFs('rush', 2000, 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url reached,  https://www.pro-football-reference.com/years/2000/passing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2001/passing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2002/passing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2003/passing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2004/passing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2005/passing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2006/passing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2007/passing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2008/passing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2009/passing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2010/passing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2011/passing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2012/passing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2013/passing.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2014/passing.htm\n",
      "finished collecting soups\n",
      "finished making dictionaries\n",
      "finished making dataframes\n",
      "\n",
      " 15 Pandas df's created, which are:\n",
      "\n",
      "dfpass_2000\n",
      "dfpass_2001\n",
      "dfpass_2002\n",
      "dfpass_2003\n",
      "dfpass_2004\n",
      "dfpass_2005\n",
      "dfpass_2006\n",
      "dfpass_2007\n",
      "dfpass_2008\n",
      "dfpass_2009\n",
      "dfpass_2010\n",
      "dfpass_2011\n",
      "dfpass_2012\n",
      "dfpass_2013\n",
      "dfpass_2014\n"
     ]
    }
   ],
   "source": [
    "# 3.  Make a list of dataframes containing Passing stats, 2018-2014\n",
    "list_df_Pass = createDFs('pass', 2000, 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url reached,  https://www.pro-football-reference.com/years/2000/receiving.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2001/receiving.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2002/receiving.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2003/receiving.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2004/receiving.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2005/receiving.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2006/receiving.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2007/receiving.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2008/receiving.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2009/receiving.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2010/receiving.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2011/receiving.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2012/receiving.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2013/receiving.htm\n",
      "url reached,  https://www.pro-football-reference.com/years/2014/receiving.htm\n",
      "finished collecting soups\n",
      "finished making dictionaries\n",
      "finished making dataframes\n",
      "\n",
      " 15 Pandas df's created, which are:\n",
      "\n",
      "dfrec_2000\n",
      "dfrec_2001\n",
      "dfrec_2002\n",
      "dfrec_2003\n",
      "dfrec_2004\n",
      "dfrec_2005\n",
      "dfrec_2006\n",
      "dfrec_2007\n",
      "dfrec_2008\n",
      "dfrec_2009\n",
      "dfrec_2010\n",
      "dfrec_2011\n",
      "dfrec_2012\n",
      "dfrec_2013\n",
      "dfrec_2014\n"
     ]
    }
   ],
   "source": [
    "#4.  Make a list of dataframes containing Receiving stats, 2018-2014\n",
    "list_df_Rec = createDFs('rec',2000, 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning ['Player']\n",
      "cleaning ['Player']\n",
      "cleaning ['Player']\n"
     ]
    }
   ],
   "source": [
    "#5.  Clean up Player names\n",
    "list_df_Pass_tmp = cleaningupColumn(list_df_Pass, ['Player'])\n",
    "list_df_Rec_tmp = cleaningupColumn(list_df_Rec, ['Player'])\n",
    "list_df_Rush_tmp = cleaningupColumn(list_df_Rush, ['Player'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.  Merge Rush, Pass, and Rec Stats together\n",
    "list_df_Pass_clean = getdfNameYardsTd(list_df_Pass_tmp)\n",
    "list_df_Rush_clean = getdfNameYardsTd(list_df_Rush_tmp)\n",
    "list_df_Rec_clean = getdfNameYardsTd(list_df_Rec_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of new QB dataframes:\n",
      " (18, 13)\n",
      "dimension of new QB dataframes:\n",
      " (18, 13)\n",
      "dimension of new QB dataframes:\n",
      " (14, 13)\n",
      "dimension of new QB dataframes:\n",
      " (16, 13)\n",
      "dimension of new QB dataframes:\n",
      " (21, 13)\n",
      "dimension of new QB dataframes:\n",
      " (23, 13)\n",
      "dimension of new QB dataframes:\n",
      " (23, 13)\n",
      "dimension of new QB dataframes:\n",
      " (20, 13)\n",
      "dimension of new QB dataframes:\n",
      " (20, 13)\n",
      "dimension of new QB dataframes:\n",
      " (21, 13)\n",
      "dimension of new QB dataframes:\n",
      " (18, 13)\n",
      "dimension of new QB dataframes:\n",
      " (18, 13)\n",
      "dimension of new QB dataframes:\n",
      " (19, 13)\n",
      "dimension of new QB dataframes:\n",
      " (16, 13)\n",
      "dimension of new QB dataframes:\n",
      " (19, 13)\n",
      "dimension of new RB dataframes:\n",
      " (34, 13)\n",
      "dimension of new RB dataframes:\n",
      " (20, 13)\n",
      "dimension of new RB dataframes:\n",
      " (36, 13)\n",
      "dimension of new RB dataframes:\n",
      " (24, 13)\n",
      "dimension of new RB dataframes:\n",
      " (22, 13)\n",
      "dimension of new RB dataframes:\n",
      " (28, 13)\n",
      "dimension of new RB dataframes:\n",
      " (25, 13)\n",
      "dimension of new RB dataframes:\n",
      " (28, 13)\n",
      "dimension of new RB dataframes:\n",
      " (30, 13)\n",
      "dimension of new RB dataframes:\n",
      " (26, 13)\n",
      "dimension of new RB dataframes:\n",
      " (25, 13)\n",
      "dimension of new RB dataframes:\n",
      " (34, 13)\n",
      "dimension of new RB dataframes:\n",
      " (27, 13)\n",
      "dimension of new RB dataframes:\n",
      " (33, 13)\n",
      "dimension of new RB dataframes:\n",
      " (32, 13)\n",
      "dimension of new WR dataframes:\n",
      " (45, 13)\n",
      "dimension of new WR dataframes:\n",
      " (46, 13)\n",
      "dimension of new WR dataframes:\n",
      " (37, 13)\n",
      "dimension of new WR dataframes:\n",
      " (39, 13)\n",
      "dimension of new WR dataframes:\n",
      " (50, 13)\n",
      "dimension of new WR dataframes:\n",
      " (39, 13)\n",
      "dimension of new WR dataframes:\n",
      " (41, 13)\n",
      "dimension of new WR dataframes:\n",
      " (49, 13)\n",
      "dimension of new WR dataframes:\n",
      " (53, 13)\n",
      "dimension of new WR dataframes:\n",
      " (44, 13)\n",
      "dimension of new WR dataframes:\n",
      " (46, 13)\n",
      "dimension of new WR dataframes:\n",
      " (46, 13)\n",
      "dimension of new WR dataframes:\n",
      " (47, 13)\n",
      "dimension of new WR dataframes:\n",
      " (38, 13)\n",
      "dimension of new WR dataframes:\n",
      " (49, 13)\n"
     ]
    }
   ],
   "source": [
    "#7.  Make subsets of NFL-Combine dataframes for specific positions\n",
    "list_df_Combines_QB = makeSubsetPos(list_df_Combines, ['QB'])\n",
    "list_df_Combines_RB = makeSubsetPos(list_df_Combines, ['RB'])\n",
    "list_df_Combines_WR = makeSubsetPos(list_df_Combines, ['WR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.  Clean up draft info column in list of df_Combines\n",
    "list_df_Combines_QB = addDraftInfo(list_df_Combines_QB)\n",
    "list_df_Combines_RB = addDraftInfo(list_df_Combines_RB)\n",
    "list_df_Combines_WR = addDraftInfo(list_df_Combines_WR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QB\n",
      "4yr-period 2000-2012 has 214\n",
      "4yr-period 2000-2012 has 224\n",
      "4yr-period 2000-2012 has 222\n",
      "4yr-period 2000-2012 has 221\n",
      "4yr-period 2000-2012 has 201\n",
      "4yr-period 2000-2012 has 190\n",
      "4yr-period 2000-2012 has 191\n",
      "4yr-period 2000-2012 has 202\n",
      "4yr-period 2000-2012 has 208\n",
      "4yr-period 2000-2012 has 200\n",
      "4yr-period 2000-2012 has 189\n",
      "4yr-period 2000-2012 has 190\n",
      "RB\n",
      "4yr-period 2000-2012 has 588\n",
      "4yr-period 2000-2012 has 591\n",
      "4yr-period 2000-2012 has 588\n",
      "4yr-period 2000-2012 has 597\n",
      "4yr-period 2000-2012 has 605\n",
      "4yr-period 2000-2012 has 592\n",
      "4yr-period 2000-2012 has 613\n",
      "4yr-period 2000-2012 has 608\n",
      "4yr-period 2000-2012 has 613\n",
      "4yr-period 2000-2012 has 623\n",
      "4yr-period 2000-2012 has 621\n",
      "4yr-period 2000-2012 has 625\n",
      "WR\n",
      "4yr-period 2000-2012 has 743\n",
      "4yr-period 2000-2012 has 734\n",
      "4yr-period 2000-2012 has 721\n",
      "4yr-period 2000-2012 has 726\n",
      "4yr-period 2000-2012 has 750\n",
      "4yr-period 2000-2012 has 771\n",
      "4yr-period 2000-2012 has 771\n",
      "4yr-period 2000-2012 has 792\n",
      "4yr-period 2000-2012 has 806\n",
      "4yr-period 2000-2012 has 826\n",
      "4yr-period 2000-2012 has 824\n",
      "4yr-period 2000-2012 has 836\n"
     ]
    }
   ],
   "source": [
    "#9.  Aggregate Stats(Yds+TD)-dataframes into 4-year sets \n",
    "print('QB')\n",
    "list_df_Pass_agg1234 = addYearsTD(list_df_Pass_clean, '2000', '2012')\n",
    "print('RB')\n",
    "list_df_Rush_agg1234 = addYearsTD(list_df_Rush_clean, '2000', '2012')\n",
    "print('WR')\n",
    "list_df_Rec_agg1234 = addYearsTD(list_df_Rec_clean,'2000', '2012')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Rename yrs columns\n",
    "list_df_Pass_agg1234 = renamingYrsColumns(list_df_Pass_agg1234)\n",
    "list_df_Rush_agg1234 = renamingYrsColumns(list_df_Rush_agg1234)\n",
    "list_df_Rec_agg1234 = renamingYrsColumns(list_df_Rec_agg1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 26)\n",
      "(18, 26)\n",
      "(14, 26)\n",
      "(16, 26)\n",
      "(21, 26)\n",
      "(23, 26)\n",
      "(23, 26)\n",
      "(20, 26)\n",
      "(20, 26)\n",
      "(21, 26)\n",
      "(18, 26)\n",
      "(18, 26)\n",
      "we should expect a total of 230 QBs from these df's\n",
      "(34, 26)\n",
      "(20, 26)\n",
      "(39, 26)\n",
      "(24, 26)\n",
      "(22, 26)\n",
      "(28, 26)\n",
      "(25, 26)\n",
      "(35, 26)\n",
      "(30, 26)\n",
      "(26, 26)\n",
      "(25, 26)\n",
      "(34, 26)\n",
      "we should expect a total of 342 RBs from these df's\n",
      "(45, 26)\n",
      "(46, 26)\n",
      "(37, 26)\n",
      "(39, 26)\n",
      "(50, 26)\n",
      "(40, 26)\n",
      "(41, 26)\n",
      "(65, 26)\n",
      "(53, 26)\n",
      "(44, 26)\n",
      "(49, 26)\n",
      "(46, 26)\n",
      "we should expect a total of 555 WRs from these df's\n"
     ]
    }
   ],
   "source": [
    "#11. Merge aggregated (4yr) Stats data with the NFL_combine, which filters out ones not listed in the dfcombine\n",
    "list_4yrSet_QB = mergeCombYdsTD(list_df_Combines_QB, list_df_Pass_agg1234, method='left')\n",
    "list_4yrSet_RB = mergeCombYdsTD(list_df_Combines_RB, list_df_Rush_agg1234, method='left')\n",
    "list_4yrSet_WR = mergeCombYdsTD(list_df_Combines_WR, list_df_Rec_agg1234, method='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QB\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "RB\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(4, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(8, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "WR\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(2, 26)\n",
      "(0, 26)\n",
      "(18, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(4, 26)\n",
      "(0, 26)\n"
     ]
    }
   ],
   "source": [
    "#12. Count how many duplicates (if any) in the df's \n",
    "#    Duplicates are indicated by nonzeros in the first value of the tuple \n",
    "print('QB')\n",
    "countDuplicates(list_4yrSet_QB)\n",
    "print('RB')\n",
    "countDuplicates(list_4yrSet_RB)\n",
    "print('WR')\n",
    "countDuplicates(list_4yrSet_WR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to drop all duplicates\n",
    "list_4yrSet_QB = [df.drop_duplicates() for df in list_4yrSet_QB]\n",
    "list_4yrSet_RB = [df.drop_duplicates() for df in list_4yrSet_RB]\n",
    "list_4yrSet_WR = [df.drop_duplicates() for df in list_4yrSet_WR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QB\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "RB\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(4, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(8, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "WR\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(2, 26)\n",
      "(0, 26)\n",
      "(18, 26)\n",
      "(0, 26)\n",
      "(0, 26)\n",
      "(4, 26)\n",
      "(0, 26)\n"
     ]
    }
   ],
   "source": [
    "# Check again for duplicates\n",
    "print('QB')\n",
    "countDuplicates(list_4yrSet_QB)\n",
    "print('RB')\n",
    "countDuplicates(list_4yrSet_RB)\n",
    "print('WR')\n",
    "countDuplicates(list_4yrSet_WR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>School</th>\n",
       "      <th>College</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>40yd</th>\n",
       "      <th>Vertical</th>\n",
       "      <th>Bench</th>\n",
       "      <th>Broad Jump</th>\n",
       "      <th>...</th>\n",
       "      <th>draftYr</th>\n",
       "      <th>draftStat</th>\n",
       "      <th>Yds_1</th>\n",
       "      <th>TD_1</th>\n",
       "      <th>Yds_2</th>\n",
       "      <th>TD_2</th>\n",
       "      <th>Yds_3</th>\n",
       "      <th>TD_3</th>\n",
       "      <th>Yds_4</th>\n",
       "      <th>TD_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chris Davis</td>\n",
       "      <td>WR</td>\n",
       "      <td>Florida State</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>5-10</td>\n",
       "      <td>181</td>\n",
       "      <td>4.50</td>\n",
       "      <td>35.5</td>\n",
       "      <td></td>\n",
       "      <td>115</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chris Davis</td>\n",
       "      <td>WR</td>\n",
       "      <td>Florida State</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>5-10</td>\n",
       "      <td>181</td>\n",
       "      <td>4.50</td>\n",
       "      <td>35.5</td>\n",
       "      <td></td>\n",
       "      <td>115</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>WR</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-0</td>\n",
       "      <td>197</td>\n",
       "      <td>4.44</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Yes</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>574</td>\n",
       "      <td>1</td>\n",
       "      <td>1220</td>\n",
       "      <td>7</td>\n",
       "      <td>554</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>WR</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-0</td>\n",
       "      <td>197</td>\n",
       "      <td>4.44</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Yes</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>574</td>\n",
       "      <td>1</td>\n",
       "      <td>1220</td>\n",
       "      <td>7</td>\n",
       "      <td>529</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>WR</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-0</td>\n",
       "      <td>197</td>\n",
       "      <td>4.44</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Yes</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1421</td>\n",
       "      <td>6</td>\n",
       "      <td>982</td>\n",
       "      <td>7</td>\n",
       "      <td>554</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>WR</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-0</td>\n",
       "      <td>197</td>\n",
       "      <td>4.44</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Yes</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1421</td>\n",
       "      <td>6</td>\n",
       "      <td>982</td>\n",
       "      <td>7</td>\n",
       "      <td>529</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>WR</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-0</td>\n",
       "      <td>197</td>\n",
       "      <td>4.44</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Yes</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1421</td>\n",
       "      <td>6</td>\n",
       "      <td>1220</td>\n",
       "      <td>7</td>\n",
       "      <td>554</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>WR</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-0</td>\n",
       "      <td>197</td>\n",
       "      <td>4.44</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Yes</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1421</td>\n",
       "      <td>6</td>\n",
       "      <td>1220</td>\n",
       "      <td>7</td>\n",
       "      <td>529</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>WR</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-0</td>\n",
       "      <td>197</td>\n",
       "      <td>4.44</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1002</td>\n",
       "      <td>7</td>\n",
       "      <td>574</td>\n",
       "      <td>1</td>\n",
       "      <td>982</td>\n",
       "      <td>7</td>\n",
       "      <td>554</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>WR</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-0</td>\n",
       "      <td>197</td>\n",
       "      <td>4.44</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1002</td>\n",
       "      <td>7</td>\n",
       "      <td>574</td>\n",
       "      <td>1</td>\n",
       "      <td>982</td>\n",
       "      <td>7</td>\n",
       "      <td>529</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>WR</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-0</td>\n",
       "      <td>197</td>\n",
       "      <td>4.44</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1002</td>\n",
       "      <td>7</td>\n",
       "      <td>574</td>\n",
       "      <td>1</td>\n",
       "      <td>1220</td>\n",
       "      <td>7</td>\n",
       "      <td>554</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>WR</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-0</td>\n",
       "      <td>197</td>\n",
       "      <td>4.44</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1002</td>\n",
       "      <td>7</td>\n",
       "      <td>574</td>\n",
       "      <td>1</td>\n",
       "      <td>1220</td>\n",
       "      <td>7</td>\n",
       "      <td>529</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>WR</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-0</td>\n",
       "      <td>197</td>\n",
       "      <td>4.44</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1002</td>\n",
       "      <td>7</td>\n",
       "      <td>1421</td>\n",
       "      <td>6</td>\n",
       "      <td>982</td>\n",
       "      <td>7</td>\n",
       "      <td>554</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>WR</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-0</td>\n",
       "      <td>197</td>\n",
       "      <td>4.44</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1002</td>\n",
       "      <td>7</td>\n",
       "      <td>1421</td>\n",
       "      <td>6</td>\n",
       "      <td>982</td>\n",
       "      <td>7</td>\n",
       "      <td>529</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>WR</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-0</td>\n",
       "      <td>197</td>\n",
       "      <td>4.44</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1002</td>\n",
       "      <td>7</td>\n",
       "      <td>1421</td>\n",
       "      <td>6</td>\n",
       "      <td>1220</td>\n",
       "      <td>7</td>\n",
       "      <td>554</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>WR</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-0</td>\n",
       "      <td>197</td>\n",
       "      <td>4.44</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1002</td>\n",
       "      <td>7</td>\n",
       "      <td>1421</td>\n",
       "      <td>6</td>\n",
       "      <td>1220</td>\n",
       "      <td>7</td>\n",
       "      <td>529</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>WR</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-0</td>\n",
       "      <td>197</td>\n",
       "      <td>4.44</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Yes</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>574</td>\n",
       "      <td>1</td>\n",
       "      <td>982</td>\n",
       "      <td>7</td>\n",
       "      <td>529</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>WR</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-0</td>\n",
       "      <td>197</td>\n",
       "      <td>4.44</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Yes</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>574</td>\n",
       "      <td>1</td>\n",
       "      <td>982</td>\n",
       "      <td>7</td>\n",
       "      <td>554</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Player Pos               School        College    Ht   Wt  40yd  \\\n",
       "8   Chris Davis  WR        Florida State  College Stats  5-10  181  4.50   \n",
       "9   Chris Davis  WR        Florida State  College Stats  5-10  181  4.50   \n",
       "53  Steve Smith  WR  Southern California  College Stats   6-0  197  4.44   \n",
       "52  Steve Smith  WR  Southern California  College Stats   6-0  197  4.44   \n",
       "51  Steve Smith  WR  Southern California  College Stats   6-0  197  4.44   \n",
       "50  Steve Smith  WR  Southern California  College Stats   6-0  197  4.44   \n",
       "49  Steve Smith  WR  Southern California  College Stats   6-0  197  4.44   \n",
       "48  Steve Smith  WR  Southern California  College Stats   6-0  197  4.44   \n",
       "47  Steve Smith  WR  Southern California  College Stats   6-0  197  4.44   \n",
       "46  Steve Smith  WR  Southern California  College Stats   6-0  197  4.44   \n",
       "45  Steve Smith  WR  Southern California  College Stats   6-0  197  4.44   \n",
       "44  Steve Smith  WR  Southern California  College Stats   6-0  197  4.44   \n",
       "43  Steve Smith  WR  Southern California  College Stats   6-0  197  4.44   \n",
       "42  Steve Smith  WR  Southern California  College Stats   6-0  197  4.44   \n",
       "41  Steve Smith  WR  Southern California  College Stats   6-0  197  4.44   \n",
       "40  Steve Smith  WR  Southern California  College Stats   6-0  197  4.44   \n",
       "54  Steve Smith  WR  Southern California  College Stats   6-0  197  4.44   \n",
       "55  Steve Smith  WR  Southern California  College Stats   6-0  197  4.44   \n",
       "\n",
       "   Vertical Bench Broad Jump ...  draftYr draftStat Yds_1 TD_1 Yds_2 TD_2  \\\n",
       "8      35.5              115 ...     2007       Yes    38    0    31    0   \n",
       "9      35.5              115 ...     2007       Yes     3    0    31    0   \n",
       "53     38.0              120 ...     2007       Yes    63    0   574    1   \n",
       "52     38.0              120 ...     2007       Yes    63    0   574    1   \n",
       "51     38.0              120 ...     2007       Yes    63    0  1421    6   \n",
       "50     38.0              120 ...     2007       Yes    63    0  1421    6   \n",
       "49     38.0              120 ...     2007       Yes    63    0  1421    6   \n",
       "48     38.0              120 ...     2007       Yes    63    0  1421    6   \n",
       "47     38.0              120 ...     2007       Yes  1002    7   574    1   \n",
       "46     38.0              120 ...     2007       Yes  1002    7   574    1   \n",
       "45     38.0              120 ...     2007       Yes  1002    7   574    1   \n",
       "44     38.0              120 ...     2007       Yes  1002    7   574    1   \n",
       "43     38.0              120 ...     2007       Yes  1002    7  1421    6   \n",
       "42     38.0              120 ...     2007       Yes  1002    7  1421    6   \n",
       "41     38.0              120 ...     2007       Yes  1002    7  1421    6   \n",
       "40     38.0              120 ...     2007       Yes  1002    7  1421    6   \n",
       "54     38.0              120 ...     2007       Yes    63    0   574    1   \n",
       "55     38.0              120 ...     2007       Yes    63    0   574    1   \n",
       "\n",
       "   Yds_3 TD_3 Yds_4 TD_4  \n",
       "8    NaN  NaN   NaN  NaN  \n",
       "9    NaN  NaN   NaN  NaN  \n",
       "53  1220    7   554    2  \n",
       "52  1220    7   529    3  \n",
       "51   982    7   554    2  \n",
       "50   982    7   529    3  \n",
       "49  1220    7   554    2  \n",
       "48  1220    7   529    3  \n",
       "47   982    7   554    2  \n",
       "46   982    7   529    3  \n",
       "45  1220    7   554    2  \n",
       "44  1220    7   529    3  \n",
       "43   982    7   554    2  \n",
       "42   982    7   529    3  \n",
       "41  1220    7   554    2  \n",
       "40  1220    7   529    3  \n",
       "54   982    7   529    3  \n",
       "55   982    7   554    2  \n",
       "\n",
       "[18 rows x 26 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show duplicated entries\n",
    "findDuplicates(list_4yrSet_WR[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Duplicates after checking for accuracy in the source websites\n",
    "list_4yrSet_RB[2] = list_4yrSet_RB[2].drop([36,37,38])             # \n",
    "list_4yrSet_RB[7] = list_4yrSet_RB[7].drop([18,19,20,21,22,23,24]) # Adrian Peterson\n",
    "list_4yrSet_RB[5] = list_4yrSet_RB[5].drop([12])                   # Chris Henry\n",
    "list_4yrSet_WR[7] = list_4yrSet_WR[7].drop([9])                    # Chris Davis\n",
    "list_4yrSet_WR[7] = list_4yrSet_WR[7].drop([55,54,40,41,42,43,44,45,46,47,48,49,50,51,53]) # Steve Smith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect and preprocessing Salary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Collect list of base salaries\n",
    "list_df_Salaries = createDFsalaries(2003, 2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/list_df_Salaries_2003_2018.pkl', 'wb') as f:\n",
    "    pickle.dump(list_df_Salaries, f)\n",
    "    \n",
    "# with open('./data/list_df_Salaries_2003_2018.pkl', 'rb') as f:\n",
    "#     list_df_Salaries = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Concatenate Salaries into a dataframe \n",
    "df_Salary_agg = bindSal(list_df_Salaries, 2003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Adjust past years salaries, based on US inflation rates  \n",
    "df_Salary_agg = includeInflation(df_Salary_agg, 2003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining Salary with Stats dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Joining stats data with 5th year salary\n",
    "list_data_QB = bindingSaltoStat(list_4yrSet_QB, df_Salary_agg, method='left')\n",
    "list_data_RB = bindingSaltoStat(list_4yrSet_RB, df_Salary_agg, method='left')\n",
    "list_data_WR = bindingSaltoStat(list_4yrSet_WR, df_Salary_agg, method='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Renaming last column into \"salary\"\n",
    "list_data_QB = renameSalCol(list_data_QB)\n",
    "list_data_RB = renameSalCol(list_data_RB)\n",
    "list_data_WR = renameSalCol(list_data_WR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before removing:\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(7, 27)\n",
      "(2050, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(2, 27)\n",
      "(0, 27)\n",
      "None\n",
      "after removing dupes:\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(2, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#3a. Looking for Duplicates QB\n",
    "print('before removing:')\n",
    "print(countDuplicates(list_data_QB))\n",
    "list_data_QB = [df.drop_duplicates() for df in list_data_QB]\n",
    "print('after removing dupes:')\n",
    "print(countDuplicates(list_data_QB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop TE Alex Smith\n",
    "list_data_QB[5] = list_data_QB[5].drop([149]) # Alex smith QB not TE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before removing\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(5, 27)\n",
      "(0, 27)\n",
      "(6, 27)\n",
      "(0, 27)\n",
      "(4, 27)\n",
      "(6, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(2, 27)\n",
      "None\n",
      "after removing\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(2, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#3b. Looking for duplicates RB\n",
    "print('before removing')\n",
    "print(countDuplicates(list_data_RB))\n",
    "list_data_RB = [df.drop_duplicates() for df in list_data_RB]\n",
    "print('after removing')\n",
    "print(countDuplicates(list_data_RB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Lorenzo Booker\n",
    "findDuplicates(list_data_RB[7])\n",
    "list_data_RB[7] = list_data_RB[7].drop([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "(0, 27)\n",
      "(32, 27)\n",
      "(2, 27)\n",
      "(0, 27)\n",
      "(2, 27)\n",
      "(12, 27)\n",
      "(4, 27)\n",
      "(32, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(16, 27)\n",
      "(0, 27)\n",
      "None\n",
      "after\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(4, 27)\n",
      "(2, 27)\n",
      "(2, 27)\n",
      "(0, 27)\n",
      "(0, 27)\n",
      "(4, 27)\n",
      "(0, 27)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#3c. Looking for duplicates WR\n",
    "print('before')\n",
    "print(countDuplicates(list_data_WR))\n",
    "list_data_WR = [df.drop_duplicates() for df in list_data_WR]\n",
    "print('after')\n",
    "print(countDuplicates(list_data_WR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>School</th>\n",
       "      <th>College</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>40yd</th>\n",
       "      <th>Vertical</th>\n",
       "      <th>Bench</th>\n",
       "      <th>Broad Jump</th>\n",
       "      <th>...</th>\n",
       "      <th>draftStat</th>\n",
       "      <th>Yds_1</th>\n",
       "      <th>TD_1</th>\n",
       "      <th>Yds_2</th>\n",
       "      <th>TD_2</th>\n",
       "      <th>Yds_3</th>\n",
       "      <th>TD_3</th>\n",
       "      <th>Yds_4</th>\n",
       "      <th>TD_4</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Mike Williams</td>\n",
       "      <td>WR</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-1</td>\n",
       "      <td>221</td>\n",
       "      <td>4.53</td>\n",
       "      <td>33.5</td>\n",
       "      <td>8</td>\n",
       "      <td>116</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>751</td>\n",
       "      <td>2</td>\n",
       "      <td>771</td>\n",
       "      <td>3</td>\n",
       "      <td>996</td>\n",
       "      <td>9</td>\n",
       "      <td>216</td>\n",
       "      <td>2</td>\n",
       "      <td>7740000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Mike Williams</td>\n",
       "      <td>WR</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-1</td>\n",
       "      <td>221</td>\n",
       "      <td>4.53</td>\n",
       "      <td>33.5</td>\n",
       "      <td>8</td>\n",
       "      <td>116</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>751</td>\n",
       "      <td>2</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>996</td>\n",
       "      <td>9</td>\n",
       "      <td>216</td>\n",
       "      <td>2</td>\n",
       "      <td>7740000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Mike Williams</td>\n",
       "      <td>WR</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-1</td>\n",
       "      <td>221</td>\n",
       "      <td>4.53</td>\n",
       "      <td>33.5</td>\n",
       "      <td>8</td>\n",
       "      <td>116</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>964</td>\n",
       "      <td>11</td>\n",
       "      <td>771</td>\n",
       "      <td>3</td>\n",
       "      <td>996</td>\n",
       "      <td>9</td>\n",
       "      <td>216</td>\n",
       "      <td>2</td>\n",
       "      <td>7740000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Mike Williams</td>\n",
       "      <td>WR</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>College Stats</td>\n",
       "      <td>6-1</td>\n",
       "      <td>221</td>\n",
       "      <td>4.53</td>\n",
       "      <td>33.5</td>\n",
       "      <td>8</td>\n",
       "      <td>116</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>964</td>\n",
       "      <td>11</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>996</td>\n",
       "      <td>9</td>\n",
       "      <td>216</td>\n",
       "      <td>2</td>\n",
       "      <td>7740000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Player Pos    School        College   Ht   Wt  40yd Vertical Bench  \\\n",
       "43  Mike Williams  WR  Syracuse  College Stats  6-1  221  4.53     33.5     8   \n",
       "47  Mike Williams  WR  Syracuse  College Stats  6-1  221  4.53     33.5     8   \n",
       "51  Mike Williams  WR  Syracuse  College Stats  6-1  221  4.53     33.5     8   \n",
       "55  Mike Williams  WR  Syracuse  College Stats  6-1  221  4.53     33.5     8   \n",
       "\n",
       "   Broad Jump    ...     draftStat Yds_1 TD_1 Yds_2 TD_2 Yds_3 TD_3 Yds_4  \\\n",
       "43        116    ...           Yes   751    2   771    3   996    9   216   \n",
       "47        116    ...           Yes   751    2   236    1   996    9   216   \n",
       "51        116    ...           Yes   964   11   771    3   996    9   216   \n",
       "55        116    ...           Yes   964   11   236    1   996    9   216   \n",
       "\n",
       "   TD_4     Salary  \n",
       "43    2  7740000.0  \n",
       "47    2  7740000.0  \n",
       "51    2  7740000.0  \n",
       "55    2  7740000.0  \n",
       "\n",
       "[4 rows x 27 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show duplicates\n",
    "findDuplicates(list_data_WR[10])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping more duplicates\n",
    "list_data_WR[5] = list_data_WR[5].drop([12,15,16])    # Chris Henry\n",
    "list_data_WR[6] = list_data_WR[6].drop([13])          # Derek Hagan\n",
    "list_data_WR[7] = list_data_WR[7].drop([39])          # Steve Smith \n",
    "list_data_WR[10] = list_data_WR[10].drop([43, 47,55]) # Mike Williams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n",
      "14\n",
      "16\n",
      "21\n",
      "23\n",
      "23\n",
      "20\n",
      "20\n",
      "21\n",
      "18\n",
      "18\n",
      "Total of 230\n",
      "34\n",
      "20\n",
      "36\n",
      "24\n",
      "22\n",
      "27\n",
      "25\n",
      "28\n",
      "30\n",
      "26\n",
      "25\n",
      "34\n",
      "Total of 331\n",
      "45\n",
      "46\n",
      "37\n",
      "39\n",
      "50\n",
      "39\n",
      "41\n",
      "49\n",
      "53\n",
      "44\n",
      "46\n",
      "46\n",
      "Total of 535\n"
     ]
    }
   ],
   "source": [
    "#4. Concatenate dataframes for each position\n",
    "df_Concat_QB = concatAll4YrSets(list_data_QB).reset_index()\n",
    "df_Concat_RB = concatAll4YrSets(list_data_RB).reset_index()\n",
    "df_Concat_WR = concatAll4YrSets(list_data_WR).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean dataframe further for EDA and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Fillin in NAN with zeros\n",
    "df_Concat_QB= df_Concat_QB.fillna(0)\n",
    "df_Concat_RB= df_Concat_RB.fillna(0)\n",
    "df_Concat_WR= df_Concat_WR.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67% players in 2000-2014 start years didnt make it 5 years\n",
      "67% players in 2000-2014 start years didnt make it 5 years\n",
      "68% players in 2000-2014 start years didnt make it 5 years\n"
     ]
    }
   ],
   "source": [
    "#2. Look at attrition rate, what % survive 5years in NFL\n",
    "calcDropOuts(df_Concat_QB, 2000, 2014)\n",
    "calcDropOuts(df_Concat_RB, 2000, 2014)\n",
    "calcDropOuts(df_Concat_WR, 2000, 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 29)\n",
      "(108, 29)\n",
      "(171, 29)\n"
     ]
    }
   ],
   "source": [
    "#2 (b) How many players survive 5 years?\n",
    "print(df_Concat_QB[df_Concat_QB['Salary'] != 0].shape)\n",
    "print(df_Concat_RB[df_Concat_RB['Salary'] != 0].shape)\n",
    "print(df_Concat_WR[df_Concat_WR['Salary'] != 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Convert Ht from Foot-Inches to (only) Inches\n",
    "df_Concat_QB = engineerHt(df_Concat_QB)\n",
    "df_Concat_RB = engineerHt(df_Concat_RB)\n",
    "df_Concat_WR = engineerHt(df_Concat_WR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming column name: '40yd' into dash'\n",
    "df_Concat_QB.rename(columns = {'40yd':'dash'}, inplace=True)\n",
    "df_Concat_RB.rename(columns = {'40yd':'dash'}, inplace=True)\n",
    "df_Concat_WR.rename(columns = {'40yd':'dash'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Select columns to use \n",
    "categorical_columns =['School','draftTeam', 'draftStat']\n",
    "more = ['Broad Jump','3Cone','Shuttle','Vertical', 'Bench',\n",
    "        'draftRnd','draftPick']\n",
    "\n",
    "select_columns = ['Player','ht_inch','draftTeam','draftStat','draftRnd',\n",
    "                      'Wt','dash',\n",
    "                     'Yds_1','TD_1','Yds_2','TD_2','Yds_3','TD_3',\n",
    "                     'Yds_4','TD_4','Salary']\n",
    "df_QB = df_Concat_QB[select_columns]\n",
    "df_RB = df_Concat_RB[select_columns]\n",
    "df_WR = df_Concat_WR[select_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QB: 230   RB: 331   WR: 535\n",
      "total:  1096\n"
     ]
    }
   ],
   "source": [
    "print('QB: %s   RB: %s   WR: %s' %(len(df_QB), len(df_RB), len(df_WR)))\n",
    "print('total: ', len(df_QB)+len(df_RB)+ len(df_WR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Find Players that survive 4 years, i.e., those that are receiving payment on the 4th year\n",
    "df_QB_active = df_QB[df_QB['Salary'] != 0]\n",
    "df_RB_active = df_RB[df_RB['Salary'] != 0]\n",
    "df_WR_active = df_WR[df_WR['Salary'] != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QB: 77   RB: 108   WR: 171\n",
      "total:  356\n"
     ]
    }
   ],
   "source": [
    "# How many observations do we have \n",
    "print('QB: %s   RB: %s   WR: %s' %(len(df_QB_active), len(df_RB_active), len(df_WR_active)))\n",
    "print('total: ', len(df_QB_active) +len(df_RB_active) + len(df_WR_active))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting STATS and Salaries to numeric values\n",
    "intcols = ['Yds_1', 'TD_1','Yds_2','TD_2','Yds_3','TD_3','Yds_4','TD_4']\n",
    "for col in intcols:\n",
    "    df_QB_active[col] = df_QB_active[col].astype(int)\n",
    "    df_RB_active[col] = df_RB_active[col].astype(int)\n",
    "    df_WR_active[col] = df_WR_active[col].astype(int)\n",
    "\n",
    "df_QB_active['Salary'] = df_QB_active['Salary'].astype(float)\n",
    "df_QB_active['dash'] = df_QB_active['dash'].astype(float)\n",
    "df_QB_active['draftRnd'] = df_QB_active['draftRnd'].apply(removeTh)\n",
    "\n",
    "df_RB_active['Salary'] = df_RB_active['Salary'].astype(float)\n",
    "df_RB_active['dash'] = df_RB_active['dash'].astype(float)\n",
    "df_RB_active['draftRnd'] = df_RB_active['draftRnd'].apply(removeTh)\n",
    "\n",
    "df_WR_active['Salary'] = df_WR_active['Salary'].astype(float)\n",
    "df_WR_active['dash'] = df_WR_active['dash'].astype(float)\n",
    "df_WR_active['draftRnd'] = df_WR_active['draftRnd'].apply(removeTh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_QB_active.to_csv('./data/QBactive_4th.csv')\n",
    "df_RB_active.to_csv('./data/RBactive_4th.csv')\n",
    "df_WR_active.to_csv('./data/WRactive_4th.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
